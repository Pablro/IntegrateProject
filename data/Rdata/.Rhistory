nessepropmatrix.row1<-c(prop1,prop2,prop3)
#Data proportion contain compare to 68-95-99 rule (1sig,2sig,3sig)-that should follow a normal distribution
filtered_data4<-qualityFilter3Sigma(nessedata,1)
filtered_data5<-qualityFilter3Sigma(nessedata,2)
filtered_data6<-qualityFilter3Sigma(nessedata,3)
filtnumber4<-nrow(filtered_data4)
filtnumber5<-nrow(filtered_data5)
filtnumber6<-nrow(filtered_data6)
prop4<-filtnumber4/totalnumber
prop5<-filtnumber5/totalnumber
prop6<-filtnumber6/totalnumber
nessepropmatrix.row2<-c(prop4,prop5,prop6)
#Data proportion for proposed median correction
#The media proposed by the authors is quite ambigous as it seems
#either random or empirical but not statistical based for which I search.
filtered_data7<-qualityFilterProposed(nessedata,1)
filtered_data8<-qualityFilterProposed(nessedata,2)
filtered_data9<-qualityFilterProposed(nessedata,3)
filtnumber7<-nrow(filtered_data7)
filtnumber8<-nrow(filtered_data8)
filtnumber9<-nrow(filtered_data9)
prop7<-filtnumber7/totalnumber
prop8<-filtnumber8/totalnumber
prop9<-filtnumber9/totalnumber
nessepropmatrix.row3<-c(prop7,prop8,prop9)
#Final matrix
nessepropmatrix<-rbind(nessepropmatrix.row1,nessepropmatrix.row2,nessepropmatrix.row3)
colnames(nessepropmatrix)<-c("1*sigma","2*sigma","3*sigma")
rownames(nessepropmatrix)<-c("AuthorsContigMedian_trimming","SigmaTrimming_NoConigTrim","Proposed_contigMedian_trimming")
#How much data/genomes the filtering conserves for this species after filtering for each method
nessepropmatrix
#How much data/genomes the filtering conserves for this species after filtering for each method
View(nessepropmatrix)
#Data proportion contain compare to 68-95-99 rule (1sig,2sig,3sig)-that should follow a normal distribution
filtered_data4<-qualityFilter3Sigma(nessedata,1)
filtered_data5<-qualityFilter3Sigma(nessedata,2)
filtered_data6<-qualityFilter3Sigma(nessedata,3)
filtnumber4<-nrow(filtered_data4)
filtnumber5<-nrow(filtered_data5)
filtnumber6<-nrow(filtered_data6)
prop4<-filtnumber4/totalnumber
prop5<-filtnumber5/totalnumber
prop6<-filtnumber6/totalnumber
nessepropmatrix.row2<-c(prop4,prop5,prop6)
#Data proportion for proposed median correction
#The media proposed by the authors is quite ambigous as it seems
#either random or empirical but not statistical based for which I search.
filtered_data7<-qualityFilterProposed(nessedata,1)
filtered_data8<-qualityFilterProposed(nessedata,2)
filtered_data9<-qualityFilterProposed(nessedata,3)
filtnumber7<-nrow(filtered_data7)
filtnumber8<-nrow(filtered_data8)
filtnumber9<-nrow(filtered_data9)
prop7<-filtnumber7/totalnumber
prop8<-filtnumber8/totalnumber
prop9<-filtnumber9/totalnumber
nessepropmatrix.row3<-c(prop7,prop8,prop9)
#Final matrix
nessepropmatrix<-rbind(nessepropmatrix.row1,nessepropmatrix.row2,nessepropmatrix.row3)
colnames(nessepropmatrix)<-c("1*sigma","2*sigma","3*sigma")
rownames(nessepropmatrix)<-c("AuthorsContigMedian_trimming","SigmaTrimming_NoConigTrim","Proposed_contigMedian_trimming")
#How much data/genomes the filtering conserves for this species after filtering for each method
View(nessepropmatrix)
#####
#So in general more genome information is gain with the proposed method based on the assumtpion of normality.
#rather than using the author default contig median trimming method.
####
# What is the visual difference?
par(mfcol=c(1,2))
#Bacteroides fragilis
median1=median(bacterodata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
n1=nrow(bacterodata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
#what effect does the threshold has in the downstream analyis?
barplot(bacterodata$Contigs,space=c(0,0)) #Does all low values contigs are okay? probably yes, depending in the sequencing technology used
index<- rep(median1,length(bacterodata$Contigs))
index2<- rep(authorthreshold,length(bacterodata$Contigs))
index3<- rep(proposedthreshold,length(bacterodata$Contigs))
lines(index,col="red") #median
lines(index2,col="green") #threshold author
lines(index3,col="blue") #threshold proposed
legend(x = "topright",legend = c("median", "Author threshold","proposed threshold"),lty = c(1,1,1),col = c("red","green","blue"),lwd = 0.5,cex=0.5)
median1=median(nessedata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
authorthreshold
n1=nrow(nessedata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
proposedthreshold
#what effect does the threshold has in the downstream analyis?
barplot(nessedata$Contigs,space = c(0,0),ylim=c(0,1500)) #Does all low values contigs are okay? Yes
index<- rep(median1,length(nessedata$Contigs))
index2<- rep(authorthreshold,length(nessedata$Contigs))
index3<- rep(proposedthreshold,length(nessedata$Contigs))
lines(index,col="red") #median
lines(index2,col="green") #threshold author
lines(index3,col="blue") #threshold proposed
legend(x = "topright",legend = c("median", "Author threshold","proposed threshold"),lty = c(1,1,1),col = c("red","green","blue"),lwd = 0.5,cex=0.3)
#####
#So in general more genome information is gain with the proposed method based on the assumtpion of normality.
#rather than using the author default contig median trimming method.
####
# What is the visual difference?
par(mfcol=c(1,2))
#Bacteroides fragilis
median1=median(bacterodata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
n1=nrow(bacterodata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
#what effect does the threshold has in the downstream analyis?
barplot(bacterodata$Contigs,space=c(0,0),main="Bacteroides fragilis, Contigs thresholds") #Does all low values contigs are okay? probably yes, depending in the sequencing technology used
index<- rep(median1,length(bacterodata$Contigs))
index2<- rep(authorthreshold,length(bacterodata$Contigs))
index3<- rep(proposedthreshold,length(bacterodata$Contigs))
#####
#So in general more genome information is gain with the proposed method based on the assumtpion of normality.
#rather than using the author default contig median trimming method.
####
# What is the visual difference?
par(mfcol=c(1,2))
#Bacteroides fragilis
median1=median(bacterodata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
n1=nrow(bacterodata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
#what effect does the threshold has in the downstream analyis?
barplot(bacterodata$Contigs,space=c(0,0),main="Bacteroides fragilis",ylab = "nr contigs", xlab="sample") #Does all low values contigs are okay? probably yes, depending in the sequencing technology used
index<- rep(median1,length(bacterodata$Contigs))
index2<- rep(authorthreshold,length(bacterodata$Contigs))
index3<- rep(proposedthreshold,length(bacterodata$Contigs))
lines(index,col="red") #median
lines(index2,col="green") #threshold author
lines(index3,col="blue") #threshold proposed
legend(x = "topright",legend = c("median", "Author threshold","proposed threshold"),lty = c(1,1,1),col = c("red","green","blue"),lwd = 0.5,cex=0.5)
median1=median(nessedata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
authorthreshold
n1=nrow(nessedata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
proposedthreshold
#what effect does the threshold has in the downstream analyis?
barplot(nessedata$Contigs,space = c(0,0),ylim=c(0,1500),main = main="Neisseria meningitidis",ylab="nr contigs",xlab="sample") #Does all low values contigs are okay? Yes
index<- rep(median1,length(nessedata$Contigs))
index2<- rep(authorthreshold,length(nessedata$Contigs))
index3<- rep(proposedthreshold,length(nessedata$Contigs))
lines(index,col="red") #median
lines(index2,col="green") #threshold author
lines(index3,col="blue") #threshold proposed
legend(x = "topright",legend = c("median", "Author threshold","proposed threshold"),lty = c(1,1,1),col = c("red","green","blue"),lwd = 0.5,cex=0.3)
#Conclusion:
#Conclusion:
#Population structure is imporant to assess the best trimming strategy. Because of the normality assumption in the used methods.
#Conclusion:
#Population structure is imporant to assess the best trimming strategy. Because of the normality assumption in the used methods.
#The proposed method account better for the normality assumption and trims better the data. It seens to be like a robust statistic.
#Conclusion:
#Population structure is imporant to assess the best trimming strategy. Because of the normality assumption in the used methods.
#The proposed method account better for the normality assumption and trims better the data. It seens to be like a robust statistic.
# yet if normality assumption is the best way to preprocess the data is still dubious as previously shown. Choosing a logical statistical approach matters
#Conclusion:
#Population structure is imporant to assess the best trimming strategy. Because of the normality assumption in the used methods.
#The proposed method account better for the normality assumption and trims better the data. It seens to be like a robust statistic.
# yet if normality assumption is the best way to preprocess the data is still dubious as previously shown. Choosing a logical statistical approach matters
#for the preprocessing
#Conclusion:
#Population structure is imporant to assess the best trimming strategy. Because of the normality assumption in the used methods.
#The proposed method account better for the normality assumption and trims better the data. It seens to be like a robust statistic.
# yet if normality assumption is the best way to preprocess the data is still dubious as previously shown. Choosing a logical statistical approach matters
#for the preprocessing
#Authors contigs filter does not seem to have a logical statistical based approach rather empirical or random approach.
#Conclusion:
#Population structure is imporant to assess the best trimming strategy. Because of the normality assumption in the used methods.
#The proposed method account better for the normality assumption and trims better the data. It seens to be like a robust statistic.
# yet if normality assumption is the best way to preprocess the data is still dubious as previously shown. Choosing a logical statistical approach matters
#for the preprocessing
#Authors contigs filter does not seem to have a logical statistical based approach rather empirical or random approach.
#This affect the proportion of genomes that is preserved for downstream analysis.
#Conclusion:
#Population structure is imporant to assess the best trimming strategy. Because of the normality assumption in the used methods.
#The proposed method account better for the normality assumption and trims better the data. It seens to be like a robust statistic.
# yet if normality assumption is the best way to preprocess the data is still dubious as previously shown. Choosing a logical statistical approach matters
#for the preprocessing
#Authors contigs filter does not seem to have a logical statistical based approach rather empirical or random approach.
#This affect the proportion of genomes that is preserved for downstream analysis.
# Having a large threshold might not be wrong but further analysis and proves would need to be shown. For example,
#Conclusion:
#Population structure is imporant to assess the best trimming strategy. Because of the normality assumption in the used methods.
#The proposed method account better for the normality assumption and trims better the data. It seens to be like a robust statistic.
# yet if normality assumption is the best way to preprocess the data is still dubious as previously shown. Choosing a logical statistical approach matters
#for the preprocessing
#Authors contigs filter does not seem to have a logical statistical based approach rather empirical or random approach.
#This affect the proportion of genomes that is preserved for downstream analysis.
# Having a large threshold might not be wrong but further analysis and proves would need to be shown. For example,
#In general and based in this observations using the proposed  preprocessing method might be a tentative option rather than using the authors method which was based in his species.
#Conclusion:
#Population structure is imporant to assess the best trimming strategy. Because of the normality assumption in the used methods.
#The proposed method account better for the normality assumption and trims better the data. It seens to be like a robust statistic.
# yet if normality assumption is the best way to preprocess the data is still dubious as previously shown. Choosing a logical statistical approach matters
#for the preprocessing
#Authors contigs filter does not seem to have a logical statistical based approach rather empirical or random approach.
#This affect the proportion of genomes that is preserved for downstream analysis.
# Having a large threshold might not be wrong but further analysis and proves would need to be shown. For example,
#In general and based in this observations using the proposed  preprocessing method might be a tentative option rather than using the authors method which was based in his species.
#And we see how species distribution has a significant impact in the preprocessing filtering for further downstream analysis.
#Population structure is imporant to assess the best trimming strategy. Because of the normality assumption in the used methods.
#The proposed method account better for the normality assumption and trims better the data. It seens to be like a robust statistic.
# yet if normality assumption is the best way to preprocess the data is still dubious as previously shown. Choosing a logical statistical approach matters
#for the preprocessing
#Authors contigs filter does not seem to have a logical statistical based approach rather empirical or random approach.
#This affect the proportion of genomes that is preserved for downstream analysis.
# Having a large threshold might not be wrong but further analysis and proves would need to be shown. For example,
#In general and based in this observations using the proposed  preprocessing method might be a tentative option rather than using the authors method which was based in his species.
#And we see how species distribution has a significant impact in the preprocessing filtering for further downstream analysis.
#Also the proposed method is still build under normality assumptions. But it improve the authors contigs filter because it seems quite ambigous.
#The proposed method account better for the normality assumption and trims better the data. It seens to be like a robust statistic.
# yet if normality assumption is the best way to preprocess the data is still dubious as previously shown. Choosing a logical statistical approach matters
#for the preprocessing
#Authors contigs filter does not seem to have a logical statistical based approach rather empirical or random approach.
#This affect the proportion of genomes that is preserved for downstream analysis.
# Having a large threshold might not be wrong but further analysis and proves would need to be shown. For example,
#In general and based in this observations using the proposed  preprocessing method might be a tentative option rather than using the authors method which was based in his species.
#And we see how species distribution has a significant impact in the preprocessing filtering for further downstream analysis.
#Also the proposed method is still build under normality assumptions. But it improve the authors contigs filter because it seems quite ambigous.
# A unsuitable cutoff value means loosing valuable information (genomes) for further downstream analysis. How to account for good genomes selection
# yet if normality assumption is the best way to preprocess the data is still dubious as previously shown. Choosing a logical statistical approach matters
#for the preprocessing
#Authors contigs filter does not seem to have a logical statistical based approach rather empirical or random approach.
#This affect the proportion of genomes that is preserved for downstream analysis.
# Having a large threshold might not be wrong but further analysis and proves would need to be shown. For example,
#In general and based in this observations using the proposed  preprocessing method might be a tentative option rather than using the authors method which was based in his species.
#And we see how species distribution has a significant impact in the preprocessing filtering for further downstream analysis.
#Also the proposed method is still build under normality assumptions. But it improve the authors contigs filter because it seems quite ambigous.
# A unsuitable cutoff value means loosing valuable information (genomes) for further downstream analysis. How to account for good genomes selection
# is still a prevailing question because we need to account for the population structure or the data distribution and the possible hidden biological concepts behind it.
# yet if normality assumption is the best way to preprocess the data is still dubious as previously shown. Choosing a logical statistical approach matters
#for the preprocessing
#Authors contigs filter does not seem to have a logical statistical based approach rather empirical or random approach.
#This affect the proportion of genomes that is preserved for downstream analysis.
# Having a large threshold might not be wrong but further analysis and proves would need to be shown. For example,
#In general and based in this observations using the proposed  preprocessing method might be a tentative option rather than using the authors method which was based in his species.
#And we see how species distribution has a significant impact in the preprocessing filtering for further downstream analysis.
#Also the proposed method is still build under normality assumptions. But it improve the authors contigs filter because it seems quite ambigous.
# A unsuitable cutoff value means loosing valuable information (genomes) for further downstream analysis. How to account for good genomes selection
# is still a prevailing question because we need to account for the population structure or the data distribution and the possible hidden biological concepts behind it.
# yet if normality assumption is the best way to preprocess the data is still dubious as previously shown. Choosing a logical statistical approach matters
#for the preprocessing
#Authors contigs filter does not seem to have a logical statistical based approach rather empirical or random approach.
#This affect the proportion of genomes that is preserved for downstream analysis.
# Having a large threshold might not be wrong but further analysis and proves would need to be shown. For example,
#In general and based in this observations using the proposed  preprocessing method might be a tentative option rather than using the authors method which was based in his species.
#And we see how species distribution has a significant impact in the preprocessing filtering for further downstream analysis.
#Also the proposed method is still build under normality assumptions. But it improve the authors contigs filter because it seems quite ambigous.
# A unsuitable cutoff value means loosing valuable information (genomes) for further downstream analysis. How to account for good genomes selection
# is still a prevailing question because we need to account for the population structure or the data distribution and the possible hidden biological concepts behind it.
#####
#So in general more genome information is gain with the proposed method based on the assumtpion of normality.
#rather than using the author default contig median trimming method.
####
# What is the visual difference?
par(mfcol=c(1,2))
#Bacteroides fragilis
median1=median(bacterodata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
n1=nrow(bacterodata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
#what effect does the threshold has in the downstream analyis?
barplot(bacterodata$Contigs,space=c(0,0),main="Bacteroides fragilis",ylab = "nr contigs", xlab="sample") #Does all low values contigs are okay? probably yes, depending in the sequencing technology used
index<- rep(median1,length(bacterodata$Contigs))
index2<- rep(authorthreshold,length(bacterodata$Contigs))
index3<- rep(proposedthreshold,length(bacterodata$Contigs))
lines(index,col="red") #median
lines(index2,col="green") #threshold author
lines(index3,col="blue") #threshold proposed
legend(x = "topright",legend = c("median", "Author threshold","proposed threshold"),lty = c(1,1,1),col = c("red","green","blue"),lwd = 0.5,cex=0.5)
median1=median(nessedata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
authorthreshold
n1=nrow(nessedata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
proposedthreshold
#what effect does the threshold has in the downstream analyis?
barplot(nessedata$Contigs,space = c(0,0),ylim=c(0,1500),main = main="Neisseria meningitidis",ylab="nr contigs",xlab="sample") #Does all low values contigs are okay? Yes
index<- rep(median1,length(nessedata$Contigs))
index2<- rep(authorthreshold,length(nessedata$Contigs))
index3<- rep(proposedthreshold,length(nessedata$Contigs))
lines(index,col="red") #median
lines(index2,col="green") #threshold author
#####
#So in general more genome information is gain with the proposed method based on the assumtpion of normality.
#rather than using the author default contig median trimming method.
####
# What is the visual difference?
par(mfcol=c(1,2))
#Bacteroides fragilis
median1=median(bacterodata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
n1=nrow(bacterodata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
#what effect does the threshold has in the downstream analyis?
barplot(bacterodata$Contigs,space=c(0,0),main="Bacteroides fragilis",ylab = "nr contigs", xlab="sample") #Does all low values contigs are okay? probably yes, depending in the sequencing technology used
index<- rep(median1,length(bacterodata$Contigs))
index2<- rep(authorthreshold,length(bacterodata$Contigs))
index3<- rep(proposedthreshold,length(bacterodata$Contigs))
lines(index,col="red") #median
lines(index2,col="green") #threshold author
lines(index3,col="blue") #threshold proposed
legend(x = "topright",legend = c("median", "Author threshold","proposed threshold"),lty = c(1,1,1),col = c("red","green","blue"),lwd = 0.5,cex=0.5)
median1=median(nessedata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
authorthreshold
n1=nrow(nessedata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
proposedthreshold
#what effect does the threshold has in the downstream analyis?
barplot(nessedata$Contigs,space = c(0,0),ylim=c(0,1500),main="Neisseria meningitidis",ylab="nr contigs",xlab="sample") #Does all low values contigs are okay? Yes
index<- rep(median1,length(nessedata$Contigs))
index2<- rep(authorthreshold,length(nessedata$Contigs))
index3<- rep(proposedthreshold,length(nessedata$Contigs))
lines(index,col="red") #median
lines(index2,col="green") #threshold author
lines(index3,col="blue") #threshold proposed
legend(x = "topright",legend = c("median", "Author threshold","proposed threshold"),lty = c(1,1,1),col = c("red","green","blue"),lwd = 0.5,cex=0.3)
#####
#So in general more genome information is gain with the proposed method based on the assumtpion of normality.
#rather than using the author default contig median trimming method.
####
# What is the visual difference?
par(mfcol=c(1,2))
#Bacteroides fragilis
median1=median(bacterodata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
n1=nrow(bacterodata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
#what effect does the threshold has in the downstream analyis?
barplot(bacterodata$Contigs,space=c(0,0),main="Bacteroides fragilis",ylab = "nr contigs", xlab="sample",cex.lab=0.8) #Does all low values contigs are okay? probably yes, depending in the sequencing technology used
#####
#So in general more genome information is gain with the proposed method based on the assumtpion of normality.
#rather than using the author default contig median trimming method.
####
# What is the visual difference?
par(mfcol=c(1,2))
#Bacteroides fragilis
median1=median(bacterodata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
n1=nrow(bacterodata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
#what effect does the threshold has in the downstream analyis?
barplot(bacterodata$Contigs,space=c(0,0),main="Bacteroides fragilis",ylab = "nr contigs", xlab="sample",cex.lab=0.3) #Does all low values contigs are okay? probably yes, depending in the sequencing technology used
#####
#So in general more genome information is gain with the proposed method based on the assumtpion of normality.
#rather than using the author default contig median trimming method.
####
# What is the visual difference?
par(mfcol=c(1,2))
#Bacteroides fragilis
median1=median(bacterodata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
n1=nrow(bacterodata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
#what effect does the threshold has in the downstream analyis?
barplot(bacterodata$Contigs,space=c(0,0),main="Bacteroides fragilis",ylab = "nr contigs", xlab="sample",cex=0.6) #Does all low values contigs are okay? probably yes, depending in the sequencing technology used
index<- rep(median1,length(bacterodata$Contigs))
#####
#So in general more genome information is gain with the proposed method based on the assumtpion of normality.
#rather than using the author default contig median trimming method.
####
# What is the visual difference?
par(mfcol=c(1,2),mgp=c(2,1,0))
#Bacteroides fragilis
median1=median(bacterodata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
n1=nrow(bacterodata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
#what effect does the threshold has in the downstream analyis?
barplot(bacterodata$Contigs,space=c(0,0),main="Bacteroides fragilis",ylab = "nr contigs", xlab="sample") #Does all low values contigs are okay? probably yes, depending in the sequencing technology used
index<- rep(median1,length(bacterodata$Contigs))
index2<- rep(authorthreshold,length(bacterodata$Contigs))
index3<- rep(proposedthreshold,length(bacterodata$Contigs))
lines(index,col="red") #median
lines(index2,col="green") #threshold author
lines(index3,col="blue") #threshold proposed
legend(x = "topright",legend = c("median", "Author threshold","proposed threshold"),lty = c(1,1,1),col = c("red","green","blue"),lwd = 0.5,cex=0.5)
median1=median(nessedata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
authorthreshold
n1=nrow(nessedata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
proposedthreshold
#what effect does the threshold has in the downstream analyis?
barplot(nessedata$Contigs,space = c(0,0),ylim=c(0,1500),main="Neisseria meningitidis",ylab="nr contigs",xlab="sample") #Does all low values contigs are okay? Yes
index<- rep(median1,length(nessedata$Contigs))
index2<- rep(authorthreshold,length(nessedata$Contigs))
index3<- rep(proposedthreshold,length(nessedata$Contigs))
lines(index,col="red") #median
lines(index2,col="green") #threshold author
lines(index3,col="blue") #threshold proposed
legend(x = "topright",legend = c("median", "Author threshold","proposed threshold"),lty = c(1,1,1),col = c("red","green","blue"),lwd = 0.5,cex=0.3)
#####
#So in general more genome information is gain with the proposed method based on the assumtpion of normality.
#rather than using the author default contig median trimming method.
####
# What is the visual difference?
par(mfcol=c(1,2),mgp=c(2,1,0))
#Bacteroides fragilis
median1=median(bacterodata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
n1=nrow(bacterodata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
#what effect does the threshold has in the downstream analyis?
barplot(bacterodata$Contigs,space=c(0,0),main="Bacteroides fragilis",ylab = "nr contigs", xlab="sample") #Does all low values contigs are okay? probably yes, depending in the sequencing technology used
index<- rep(median1,length(bacterodata$Contigs))
index2<- rep(authorthreshold,length(bacterodata$Contigs))
index3<- rep(proposedthreshold,length(bacterodata$Contigs))
lines(index,col="red") #median
lines(index2,col="green") #threshold author
lines(index3,col="blue") #threshold proposed
legend(x = "topright",legend = c("median", "Author threshold","proposed threshold"),lty = c(1,1,1),col = c("red","green","blue"),lwd = 0.5,cex=0.5)
median1=median(nessedata$Contigs)
authorthreshold=2.5*median1 #suggest by the authors. Why 2.5 and not 3. for example?
authorthreshold
n1=nrow(nessedata)
#as you can see the value 2.5 is preserved as z value but the equation change according to the reference:
#https://www.statology.org/confidence-interval-for-median/
#in this way we still assume the orginal normal distribution for the median.
#Adapted to be upper bound only-one sided
#around 99 confidence interval-still author value is used
proposedthreshold=(n1*0.5)+2.5*sqrt( n1*0.5*(1-0.5))
proposedthreshold
#what effect does the threshold has in the downstream analyis?
barplot(nessedata$Contigs,space = c(0,0),ylim=c(0,1500),main="Neisseria meningitidis",ylab="nr contigs",xlab="sample") #Does all low values contigs are okay? Yes
index<- rep(median1,length(nessedata$Contigs))
index2<- rep(authorthreshold,length(nessedata$Contigs))
index3<- rep(proposedthreshold,length(nessedata$Contigs))
lines(index,col="red") #median
lines(index2,col="green") #threshold author
lines(index3,col="blue") #threshold proposed
legend(x = "topright",legend = c("median", "Author threshold","proposed threshold"),lty = c(1,1,1),col = c("red","green","blue"),lwd = 0.5,cex=0.5)
